{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"gpuType":"A100","authorship_tag":"ABX9TyMMnteGNq4a0AFLvtPOtK01"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NCdplkjz7XsC","executionInfo":{"status":"ok","timestamp":1767599993528,"user_tz":-540,"elapsed":2071,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"4692bb46-5438-46c0-e6ef-d8cd024f9a5e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import timm\n","\n","# ==========================================\n","# ğŸ”¥ ë”¥í˜ì´í¬ íƒì§€ ëª¨ë¸ ì„¤ê³„ë„ (Class)\n","# ==========================================\n","class DeepfakeDetector(nn.Module):\n","    def __init__(self, model_name='convnextv2_base.fcmae_ft_in22k_in1k', pretrained=True):\n","        super(DeepfakeDetector, self).__init__()\n","\n","        print(f\"ğŸ—ï¸ [DeepfakeDetector] ëª¨ë¸ ìƒì„± ì¤‘... (Base: {model_name})\")\n","\n","        # 1. Backbone (ëª¸í†µ) ë¡œë“œ: ConvNeXt V2 Base\n","        # pretrained=True: ì´ë¯¸ ë˜‘ë˜‘í•œ ìƒíƒœë¡œ ê°€ì ¸ì˜´\n","        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n","\n","        # 2. ê¸°ì¡´ ë¶„ë¥˜ê¸°(Head) ì œê±° ë° ì…ë ¥ í¬ê¸° í™•ì¸\n","        # ConvNeXt V2 Baseì˜ ê²½ìš° ë³´í†µ 1024ê°œì˜ íŠ¹ì§•(Feature)ì´ ë‚˜ì˜µë‹ˆë‹¤.\n","        if hasattr(self.backbone, 'head') and hasattr(self.backbone.head, 'fc'):\n","            n_features = self.backbone.head.fc.in_features\n","            self.backbone.head.fc = nn.Identity() # ê¸°ì¡´ Head ë¬´ë ¥í™”\n","        else:\n","            # ì•ˆì „ì¥ì¹˜: í˜¹ì‹œ êµ¬ì¡°ê°€ ë‹¤ë¥¼ ê²½ìš°\n","            n_features = self.backbone.num_features\n","            self.backbone.reset_classifier(0)\n","\n","        # 3. Custom Head (ìš°ë¦¬ê°€ ì§ì ‘ íŠœë‹í•˜ëŠ” ë¨¸ë¦¬ ë¶€ë¶„)\n","        # 1024ê°œ íŠ¹ì§• -> 512 -> 128 -> 1 (ê°€ì§œ í™•ë¥ )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(n_features, 512),\n","            nn.BatchNorm1d(512),     # í•™ìŠµ ì•ˆì •í™”\n","            nn.ReLU(),\n","            nn.Dropout(0.5),         # ê³¼ì í•© ë°©ì§€ (ì¤‘ìš”!)\n","\n","            nn.Linear(512, 128),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","\n","            nn.Linear(128, 1)        # ìµœì¢… ê²°ê³¼ (0~1 ì‚¬ì´ ê°’ ì¶œë ¥ ì˜ˆì •)\n","        )\n","\n","    def forward(self, x):\n","        # ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¤ë©´ -> ëª¸í†µ í†µê³¼ -> íŠ¹ì§• ì¶”ì¶œ -> ë‚´ ë¶„ë¥˜ê¸° í†µê³¼ -> ê²°ê³¼\n","        features = self.backbone(x)\n","        output = self.classifier(features)\n","        return output\n","\n","    # [ì˜µì…˜] ëª¸í†µ ì–¼ë¦¬ê¸° ê¸°ëŠ¥ (ì²˜ìŒì—” Headë§Œ í•™ìŠµì‹œí‚¬ ë•Œ ì‚¬ìš©)\n","    def freeze_backbone(self):\n","        for param in self.backbone.parameters():\n","            param.requires_grad = False\n","        print(\"â„ï¸ Backbone(ëª¸í†µ)ì„ ì–¼ë ¸ìŠµë‹ˆë‹¤. (Headë§Œ í•™ìŠµë©ë‹ˆë‹¤)\")\n","\n","    # [ì˜µì…˜] ëª¸í†µ ë…¹ì´ê¸° ê¸°ëŠ¥ (ë‚˜ì¤‘ì— ì „ì²´ ë¯¸ì„¸ ì¡°ì •í•  ë•Œ ì‚¬ìš©)\n","    def unfreeze_backbone(self):\n","        for param in self.backbone.parameters():\n","            param.requires_grad = True\n","        print(\"â˜€ï¸ Backbone(ëª¸í†µ)ì„ ë…¹ì˜€ìŠµë‹ˆë‹¤. (ì „ì²´ í•™ìŠµ ê°€ëŠ¥)\")"],"metadata":{"id":"A04k2EDu76Il"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1. ë°ì´í„° ë¡œë”(DataLoader ì„¤ì •)"],"metadata":{"id":"7v3SkvlhHGJ5"}},{"cell_type":"code","source":["import os\n","import shutil\n","from google.colab import files\n","\n","# ==========================================\n","# 1. ì €ì¥ ê²½ë¡œ ì„¤ì • (ë¡œì»¬ SSD)\n","# ==========================================\n","local_path = '/content/local_data'\n","# ê¸°ì¡´ì— ë³µì‚¬í•˜ë‹¤ ë§Œ ì°Œêº¼ê¸°ê°€ ìˆë‹¤ë©´ ì‚­ì œ\n","if os.path.exists(local_path):\n","    shutil.rmtree(local_path)\n","os.makedirs(local_path, exist_ok=True)\n","\n","print(f\"ğŸš€ [ì´ˆê³ ì†] Kaggleì—ì„œ ë°ì´í„°ë¥¼ ì½”ë© SSDë¡œ ì§ì ‘ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\")\n","print(f\"   ğŸ‘‰ ì €ì¥ ìœ„ì¹˜: {local_path}\")\n","\n","# ==========================================\n","# 2. Kaggle ì¸ì¦ í™•ì¸ (ì—†ìœ¼ë©´ ì—…ë¡œë“œ)\n","# ==========================================\n","# kaggle.jsonì´ ì—†ìœ¼ë©´ ë‹¤ì‹œ ì—…ë¡œë“œ ìš”ì²­\n","if not os.path.exists('/root/.kaggle/kaggle.json'):\n","    print(\"\\nğŸ”‘ kaggle.json íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. íŒŒì¼ ì„ íƒ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.\")\n","    uploaded = files.upload()\n","    for fn in uploaded.keys():\n","        print(f'âœ… ì—…ë¡œë“œ í™•ì¸: \"{fn}\"')\n","    !mkdir -p ~/.kaggle\n","    !mv kaggle.json ~/.kaggle/\n","    !chmod 600 ~/.kaggle/kaggle.json\n","else:\n","    print(\"âœ… Kaggle ì¸ì¦ ì •ë³´ê°€ ì´ë¯¸ ìˆìŠµë‹ˆë‹¤. ë°”ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\")\n","\n","# ==========================================\n","# 3. ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ\n","# ==========================================\n","print(\"\\nâ¬‡ï¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘... (ì•½ 1~2ë¶„ ì†Œìš”)\")\n","# -d: ë°ì´í„°ì…‹ ID, -p: ì €ì¥ ê²½ë¡œ, --unzip: ìë™ ì••ì¶• í•´ì œ\n","!kaggle datasets download -d manjilkarki/deepfake-and-real-images -p {local_path} --unzip\n","\n","# ==========================================\n","# 4. í´ë” êµ¬ì¡° ì •ë¦¬ (ì¤‘ìš”!)\n","# ==========================================\n","# ì••ì¶•ì´ í’€ë¦¬ë©´ 'Dataset/Train' í´ë”ê°€ ìƒê¹ë‹ˆë‹¤.\n","# ìš°ë¦¬ê°€ ì›í•˜ëŠ” ê²½ë¡œëŠ” '/content/local_data/Train' ì…ë‹ˆë‹¤.\n","\n","final_train_path = os.path.join(local_path, 'Train')\n","extracted_train_path = os.path.join(local_path, 'Dataset', 'Train')\n","\n","if os.path.exists(extracted_train_path):\n","    print(\"\\nğŸ“¦ í´ë” êµ¬ì¡°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤...\")\n","    # Dataset/Train -> Train ìœ¼ë¡œ ì´ë™\n","    shutil.move(extracted_train_path, local_path)\n","    # ë¹ˆ í´ë” ì‚­ì œ\n","    shutil.rmtree(os.path.join(local_path, 'Dataset'))\n","\n","    # Validationìš© í´ë”ê°€ ìˆë‹¤ë©´ ê·¸ê²ƒë„ ì •ë¦¬ (ì„ íƒì‚¬í•­)\n","    extracted_val_path = os.path.join(local_path, 'Dataset', 'Validation')\n","    if os.path.exists(extracted_val_path):\n","         shutil.rmtree(extracted_val_path) # ìš°ë¦° Trainë§Œ ì“¸ ê±°ë‹ˆê¹Œ ì‚­ì œí•´ì„œ ìš©ëŸ‰ í™•ë³´\n","\n","print(\"\\n\" + \"=\"*50)\n","print(f\"âœ… ì¤€ë¹„ ì™„ë£Œ!\")\n","print(f\"ğŸ“Š ì €ì¥ëœ íŒŒì¼ í™•ì¸:\")\n","# íŒŒì¼ ìˆ˜ ì„¸ê¸°\n","count = sum([len(files) for r, d, files in os.walk(final_train_path)])\n","print(f\"   ğŸ‘‰ ì´ ì´ë¯¸ì§€ ìˆ˜: {count:,}ì¥\")\n","print(f\"   ğŸ‘‰ ê²½ë¡œ: {final_train_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"id":"GCL_HbYZtbq1","executionInfo":{"status":"ok","timestamp":1767611906259,"user_tz":-540,"elapsed":50709,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"f95464c3-4976-46b6-92eb-e917e9880344"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸš€ [ì´ˆê³ ì†] Kaggleì—ì„œ ë°ì´í„°ë¥¼ ì½”ë© SSDë¡œ ì§ì ‘ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\n","   ğŸ‘‰ ì €ì¥ ìœ„ì¹˜: /content/local_data\n","\n","ğŸ”‘ kaggle.json íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. íŒŒì¼ ì„ íƒ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-5949b7f5-af28-497b-babc-9db4bced7369\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-5949b7f5-af28-497b-babc-9db4bced7369\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n","âœ… ì—…ë¡œë“œ í™•ì¸: \"kaggle.json\"\n","\n","â¬‡ï¸ ë‹¤ìš´ë¡œë“œ ì‹œì‘... (ì•½ 1~2ë¶„ ì†Œìš”)\n","Dataset URL: https://www.kaggle.com/datasets/manjilkarki/deepfake-and-real-images\n","License(s): unknown\n","Downloading deepfake-and-real-images.zip to /content/local_data\n"," 95% 1.61G/1.68G [00:01<00:00, 969MB/s]\n","100% 1.68G/1.68G [00:01<00:00, 1.25GB/s]\n","\n","ğŸ“¦ í´ë” êµ¬ì¡°ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤...\n","\n","==================================================\n","âœ… ì¤€ë¹„ ì™„ë£Œ!\n","ğŸ“Š ì €ì¥ëœ íŒŒì¼ í™•ì¸:\n","   ğŸ‘‰ ì´ ì´ë¯¸ì§€ ìˆ˜: 140,002ì¥\n","   ğŸ‘‰ ê²½ë¡œ: /content/local_data/Train\n"]}]},{"cell_type":"markdown","source":["### {'Fake': 0, 'Real': 1} ëŒ€íšŒëŠ” ë°˜ëŒ€ì´ë¯€ë¡œ ë‚˜ì¤‘ì— ì¶”ë¡ í•œ ë‹¤ìŒ ë°˜ì „ì„ ì¤˜ì•¼í•¨"],"metadata":{"id":"g4_4AMFmw8VU"}},{"cell_type":"code","source":["import torch\n","import random\n","import numpy as np\n","import os\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, random_split\n","\n","# ==========================================\n","# 0. ì‹œë“œ(Seed) ê³ ì • í•¨ìˆ˜\n","# ==========================================\n","def set_seed(seed=42):\n","    \"\"\"\n","    ëª¨ë“  ëœë¤ ë³€ìˆ˜ë¥¼ ê³ ì •í•˜ì—¬, ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ê°™ì€ ê²°ê³¼ê°€ ë‚˜ì˜¤ë„ë¡ í•¨\n","    \"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)  # ë©€í‹° GPU ì‚¬ìš© ì‹œ\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    print(f\"ğŸ”’ ëª¨ë“  ëœë¤ ì‹œë“œê°€ {seed}ë²ˆìœ¼ë¡œ ê³ ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n","\n","# ì‹œë“œ ê³ ì • ì‹¤í–‰ (ê°€ì¥ ë¨¼ì € í˜¸ì¶œ!)\n","set_seed(42)\n","\n","# ==========================================\n","# 1. ì„¤ì • (Configuration)\n","# ==========================================\n","BATCH_SIZE = 32\n","IMG_SIZE = 224\n","# ğŸ”¥ [ì¤‘ìš”] êµ¬ê¸€ ë“œë¼ì´ë¸Œê°€ ì•„ë‹ˆë¼, ì•„ê¹Œ ë³µì‚¬í•´ë‘” 'ë¡œì»¬(SSD)' ê²½ë¡œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n","# (ì†ë„ê°€ 20ë°° ë¹¨ë¼ì§‘ë‹ˆë‹¤)\n","DATA_PATH = '/content/local_data/Train'\n","\n","# ==========================================\n","# 2. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (Transforms) - ìˆ˜ì •ë¨\n","# ==========================================\n","transform = transforms.Compose([\n","    # 1. ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ (ì§§ì€ ë³€ ê¸°ì¤€ 256px)\n","    transforms.Resize(256),\n","\n","    # 2. ì¤‘ì•™ í¬ë¡­ (ì–¼êµ´ ë¹„ìœ¨ ì™œê³¡ ì—†ì´ 224x224 ì¶”ì¶œ)\n","    transforms.CenterCrop(IMG_SIZE),\n","\n","    # 3. ë°ì´í„° ì¦ê°• (Augmentation)\n","    transforms.RandomHorizontalFlip(p=0.5), # ì¢Œìš° ë°˜ì „\n","    transforms.RandomRotation(10),          # ì‚´ì§ íšŒì „\n","\n","    # 4. í…ì„œ ë³€í™˜ ë° ì •ê·œí™”\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406],\n","                         [0.229, 0.224, 0.225])\n","])\n","\n","# ==========================================\n","# 3. ë°ì´í„°ì…‹ ë¡œë“œ ë° ë¶„í•  (8:2)\n","# ==========================================\n","print(f\"ğŸ“‚ ë°ì´í„° ë¡œë“œ ê²½ë¡œ: {DATA_PATH}\")\n","\n","# ë¡œì»¬ ê²½ë¡œì— íŒŒì¼ì´ ì§„ì§œ ìˆëŠ”ì§€ ì•ˆì „ì¥ì¹˜ í™•ì¸\n","if not os.path.exists(DATA_PATH):\n","    raise FileNotFoundError(f\"ğŸš¨ ì˜¤ë¥˜: {DATA_PATH} ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤. \\nğŸ‘‰ ì§ì „ì— ì•Œë ¤ë“œë¦° 'ë°ì´í„° ë³µì‚¬ ì½”ë“œ(!cp)'ë¥¼ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”!\")\n","\n","full_dataset = datasets.ImageFolder(root=DATA_PATH, transform=transform)\n","\n","# ì „ì²´ ë°ì´í„° ê°œìˆ˜\n","total_size = len(full_dataset)\n","train_size = int(0.8 * total_size)\n","val_size = total_size - train_size\n","\n","# ë¬´ì‘ìœ„ ë¶„í•  (ìœ„ì—ì„œ ì‹œë“œë¥¼ ê³ ì •í–ˆìœ¼ë¯€ë¡œ ë§¤ë²ˆ ë˜‘ê°™ì´ ë‚˜ë‰¨)\n","train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n","\n","# ë°ì´í„° ë¡œë” ìƒì„±\n","# num_workers=2: ë¡œì»¬ SSDì—ì„œëŠ” 2~4 ì •ë„ë©´ ì¶©ë¶„íˆ ë¹ ë¦…ë‹ˆë‹¤.\n","train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=True)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","\n","print(\"-\" * 50)\n","print(f\"âœ… ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì™„ë£Œ!\")\n","print(f\"   ğŸ‘‰ í•™ìŠµ ë°ì´í„°(Train): {len(train_dataset):,}ì¥\")\n","print(f\"   ğŸ‘‰ ê²€ì¦ ë°ì´í„°(Val):   {len(val_dataset):,}ì¥\")\n","print(f\"   ğŸ‘‰ í´ë˜ìŠ¤ ë§µí•‘: {full_dataset.class_to_idx}\")\n","# ê²°ê³¼ ì˜ˆì‹œ: {'Fake': 0, 'Real': 1}\n","print(\"-\" * 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RM0g910zGe_f","executionInfo":{"status":"ok","timestamp":1767612695342,"user_tz":-540,"elapsed":350,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"528f4502-7d34-494e-cf6e-ea75af08896d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ”’ ëª¨ë“  ëœë¤ ì‹œë“œê°€ 42ë²ˆìœ¼ë¡œ ê³ ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\n","ğŸ“‚ ë°ì´í„° ë¡œë“œ ê²½ë¡œ: /content/local_data/Train\n","--------------------------------------------------\n","âœ… ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ ì™„ë£Œ!\n","   ğŸ‘‰ í•™ìŠµ ë°ì´í„°(Train): 112,001ì¥\n","   ğŸ‘‰ ê²€ì¦ ë°ì´í„°(Val):   28,001ì¥\n","   ğŸ‘‰ í´ë˜ìŠ¤ ë§µí•‘: {'Fake': 0, 'Real': 1}\n","--------------------------------------------------\n"]}]},{"cell_type":"markdown","source":["## 2. í•™ìŠµ ë° ê²€ì¦ í•¨ìˆ˜(Trainer)"],"metadata":{"id":"VYNtRIKPHTq9"}},{"cell_type":"code","source":["import torch.optim as optim\n","from tqdm import tqdm\n","\n","# ì†ì‹¤ í•¨ìˆ˜: ì´ì§„ ë¶„ë¥˜(Binary Classification)ì´ë¯€ë¡œ BCEWithLogitsLoss ì‚¬ìš©\n","criterion = torch.nn.BCEWithLogitsLoss()\n","\n","def train_one_epoch(model, loader, optimizer, device):\n","    model.train() # í•™ìŠµ ëª¨ë“œ ì „í™˜\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    loop = tqdm(loader, leave=True) # ì§„í–‰ë°” í‘œì‹œ\n","\n","    for images, labels in loop:\n","        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n","\n","        # 1. ì˜ˆì¸¡ (Forward)\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        # 2. ì—­ì „íŒŒ (Backward)\n","        optimizer.zero_grad() # ì´ì „ ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n","        loss.backward()       # ê¸°ìš¸ê¸° ê³„ì‚°\n","        optimizer.step()      # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n","\n","        # 3. í†µê³„ ê³„ì‚°\n","        running_loss += loss.item()\n","\n","        # í™•ë¥ ì´ 0.5 ì´ìƒì´ë©´ 1(Real/Fake), ì•„ë‹ˆë©´ 0ìœ¼ë¡œ íŒë‹¨\n","        predicted = (torch.sigmoid(outputs) > 0.5).float()\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","        # ì§„í–‰ë°”ì— ì‹¤ì‹œê°„ ì •í™•ë„ í‘œì‹œ\n","        loop.set_description(f\"Train Loss: {loss.item():.4f}\")\n","\n","    avg_loss = running_loss / len(loader)\n","    acc = 100 * correct / total\n","    return avg_loss, acc\n","\n","def evaluate(model, loader, device):\n","    model.eval() # í‰ê°€ ëª¨ë“œ (Dropout êº¼ì§)\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad(): # í‰ê°€ ë• ê¸°ìš¸ê¸° ê³„ì‚° X (ë©”ëª¨ë¦¬ ì ˆì•½)\n","        for images, labels in loader:\n","            images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n","\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item()\n","            predicted = (torch.sigmoid(outputs) > 0.5).float()\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    avg_loss = running_loss / len(loader)\n","    acc = 100 * correct / total\n","    return avg_loss, acc"],"metadata":{"id":"kLOI4HTAHRsK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. ë©”ì¸ ì‹¤í–‰"],"metadata":{"id":"R_9AzZlqHYmp"}},{"cell_type":"code","source":["# ==========================================\n","# ğŸ í•™ìŠµ ì‹¤í–‰ (Main Loop)\n","# ==========================================\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# 1. ëª¨ë¸ ì¤€ë¹„\n","model = DeepfakeDetector().to(device)\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"â„ï¸ [Step 1] ë°±ë³¸ ì–¼ë¦¬ê¸° í•™ìŠµ (Head Warming-up)\")\n","print(\"=\"*60)\n","\n","# ë°±ë³¸ ì–¼ë¦¬ê¸°\n","model.freeze_backbone()\n","\n","# Optimizer: Headë§Œ í•™ìŠµí•˜ë¯€ë¡œ í•™ìŠµë¥ (lr)ì„ ì¡°ê¸ˆ í¬ê²Œ(1e-3) ì¡ìŒ\n","optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n","\n","# Step 1 í•™ìŠµ (ì§§ê²Œ 1~3 ì—í­ë§Œ)\n","epochs_step1 = 2\n","\n","for epoch in range(epochs_step1):\n","    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, device)\n","    val_loss, val_acc = evaluate(model, val_loader, device)\n","\n","    print(f\"Epoch [{epoch+1}/{epochs_step1}] \"\n","          f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.2f}%  ||  \"\n","          f\"Val Loss: {val_loss:.4f} | Acc: {val_acc:.2f}%\")\n","\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"â˜€ï¸ [Step 2] ë°±ë³¸ ë…¹ì´ê¸° & ì „ì²´ ë¯¸ì„¸ì¡°ì • (Fine-Tuning)\")\n","print(\"=\"*60)\n","\n","# ë°±ë³¸ ë…¹ì´ê¸°\n","model.unfreeze_backbone()\n","\n","# Optimizer: ì „ì²´ë¥¼ í•™ìŠµí•˜ë¯€ë¡œ í•™ìŠµë¥ ì„ ì•„ì£¼ ì‘ê²Œ(1e-4 ~ 1e-5) ì¤„ì—¬ì•¼ í•¨! (ì¤‘ìš”)\n","# ê·¸ë˜ì•¼ ë°•ì‚¬ë‹˜(ë°±ë³¸)ì˜ ì§€ì‹ì´ ê¹¨ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.\n","optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n","\n","# Step 2 í•™ìŠµ (ê¸¸ê²Œ 5~10 ì—í­)\n","epochs_step2 = 5\n","\n","for epoch in range(epochs_step2):\n","    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, device)\n","    val_loss, val_acc = evaluate(model, val_loader, device)\n","\n","    print(f\"Epoch [{epoch+1}/{epochs_step2}] \"\n","          f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.2f}%  ||  \"\n","          f\"Val Loss: {val_loss:.4f} | Acc: {val_acc:.2f}%\")\n","\n","    # ëª¨ë¸ ì €ì¥ (ì„±ëŠ¥ì´ ì¢‹ì„ ë•Œë§ˆë‹¤ ì €ì¥ ì¶”ì²œ)\n","    torch.save(model.state_dict(), f\"deepfake_model_epoch_{epoch+1}.pth\")\n","\n","print(\"\\nğŸ‰ ëª¨ë“  í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h8SDcHJlHb-y","executionInfo":{"status":"ok","timestamp":1767620274774,"user_tz":-540,"elapsed":7577102,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"894b1a15-17b9-49ff-ff4f-ef3074a0bd39"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ—ï¸ [DeepfakeDetector] ëª¨ë¸ ìƒì„± ì¤‘... (Base: convnextv2_base.fcmae_ft_in22k_in1k)\n","\n","============================================================\n","â„ï¸ [Step 1] ë°±ë³¸ ì–¼ë¦¬ê¸° í•™ìŠµ (Head Warming-up)\n","============================================================\n","â„ï¸ Backbone(ëª¸í†µ)ì„ ì–¼ë ¸ìŠµë‹ˆë‹¤. (Headë§Œ í•™ìŠµë©ë‹ˆë‹¤)\n"]},{"output_type":"stream","name":"stderr","text":["Train Loss: 0.3964: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3500/3500 [05:40<00:00, 10.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/2] Train Loss: 0.3748 | Acc: 83.09%  ||  Val Loss: 0.3138 | Acc: 86.53%\n"]},{"output_type":"stream","name":"stderr","text":["Train Loss: 0.2620: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3500/3500 [05:40<00:00, 10.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/2] Train Loss: 0.3343 | Acc: 85.35%  ||  Val Loss: 0.3022 | Acc: 87.16%\n","\n","============================================================\n","â˜€ï¸ [Step 2] ë°±ë³¸ ë…¹ì´ê¸° & ì „ì²´ ë¯¸ì„¸ì¡°ì • (Fine-Tuning)\n","============================================================\n","â˜€ï¸ Backbone(ëª¸í†µ)ì„ ë…¹ì˜€ìŠµë‹ˆë‹¤. (ì „ì²´ í•™ìŠµ ê°€ëŠ¥)\n"]},{"output_type":"stream","name":"stderr","text":["Train Loss: 0.0208: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3500/3500 [21:03<00:00,  2.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/5] Train Loss: 0.0669 | Acc: 97.74%  ||  Val Loss: 0.0415 | Acc: 98.33%\n"]},{"output_type":"stream","name":"stderr","text":["Train Loss: 0.0106: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3500/3500 [21:01<00:00,  2.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/5] Train Loss: 0.0364 | Acc: 98.66%  ||  Val Loss: 0.0467 | Acc: 98.20%\n"]},{"output_type":"stream","name":"stderr","text":["Train Loss: 0.1586: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3500/3500 [21:01<00:00,  2.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/5] Train Loss: 0.0305 | Acc: 98.84%  ||  Val Loss: 0.0475 | Acc: 98.46%\n"]},{"output_type":"stream","name":"stderr","text":["Train Loss: 0.0042: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3500/3500 [21:01<00:00,  2.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/5] Train Loss: 0.0252 | Acc: 98.99%  ||  Val Loss: 0.0319 | Acc: 98.85%\n"]},{"output_type":"stream","name":"stderr","text":["Train Loss: 0.0261: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3500/3500 [21:01<00:00,  2.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/5] Train Loss: 0.0203 | Acc: 99.20%  ||  Val Loss: 0.0477 | Acc: 98.79%\n","\n","ğŸ‰ ëª¨ë“  í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"]}]},{"cell_type":"markdown","source":["## 4. í•™ìŠµëœ ëª¨ë¸ ì €ì¥"],"metadata":{"id":"LapahyWEbPn9"}},{"cell_type":"code","source":["import shutil\n","import os\n","import glob\n","\n","# 1. ì˜®ê¸¸ íŒŒì¼ë“¤ì´ ìˆëŠ” ê³³ (í˜„ì¬ ì½”ë© ì„ì‹œ ìœ„ì¹˜)\n","source_dir = '/content'\n","# 2. ì €ì¥í•  êµ¬ê¸€ ë“œë¼ì´ë¸Œ ìœ„ì¹˜\n","target_dir = '/content/drive/MyDrive/DILAB/OK/hecto-deepfake-detection/models'\n","\n","# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n","os.makedirs(target_dir, exist_ok=True)\n","\n","print(f\"ğŸšš ëª¨ë¸ êµ¬ì¡° ì‘ì „ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n","print(f\"   ëª©ì ì§€: {target_dir}\")\n","\n","# 'deepfake_model_epoch_'ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  .pth íŒŒì¼ ì°¾ê¸°\n","pth_files = glob.glob(os.path.join(source_dir, \"deepfake_model_epoch_*.pth\"))\n","\n","if len(pth_files) == 0:\n","    print(\"âŒ íŒŒì¼ì„ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤! í˜¹ì‹œ ì´ë¯¸ ì§€ì›Œì¡Œê±°ë‚˜ ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n","else:\n","    for file_path in pth_files:\n","        file_name = os.path.basename(file_path)\n","        dest_path = os.path.join(target_dir, file_name)\n","\n","        # íŒŒì¼ ì´ë™ (move) ë˜ëŠ” ë³µì‚¬ (copy)\n","        shutil.copy(file_path, dest_path)\n","        print(f\"   âœ… ì €ì¥ ì™„ë£Œ: {file_name}\")\n","\n","print(\"\\nğŸ‰ ëª¨ë“  ëª¨ë¸ì„ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¡œ ëŒ€í”¼ì‹œì¼°ìŠµë‹ˆë‹¤! ë“œë¼ì´ë¸Œ í´ë”ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oktRY9bibPbV","executionInfo":{"status":"ok","timestamp":1767621079706,"user_tz":-540,"elapsed":3745,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"fcd6a8fd-8a0e-4118-8171-7fa36fe8b266"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸšš ëª¨ë¸ êµ¬ì¡° ì‘ì „ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n","   ëª©ì ì§€: /content/drive/MyDrive/DILAB/OK/hecto-deepfake-detection/models\n","   âœ… ì €ì¥ ì™„ë£Œ: deepfake_model_epoch_5.pth\n","   âœ… ì €ì¥ ì™„ë£Œ: deepfake_model_epoch_2.pth\n","   âœ… ì €ì¥ ì™„ë£Œ: deepfake_model_epoch_4.pth\n","   âœ… ì €ì¥ ì™„ë£Œ: deepfake_model_epoch_1.pth\n","   âœ… ì €ì¥ ì™„ë£Œ: deepfake_model_epoch_3.pth\n","\n","ğŸ‰ ëª¨ë“  ëª¨ë¸ì„ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¡œ ëŒ€í”¼ì‹œì¼°ìŠµë‹ˆë‹¤! ë“œë¼ì´ë¸Œ í´ë”ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.\n"]}]},{"cell_type":"markdown","source":["# ê²€ì¦"],"metadata":{"id":"4WJ99wIgZ5T3"}},{"cell_type":"markdown","source":["## 1. Valdiation ë°ì´í„° ë³µêµ¬ (ë‹¤ìš´ë¡œë“œ)"],"metadata":{"id":"DSUU1TTdZ_7Z"}},{"cell_type":"code","source":["import os\n","import shutil\n","\n","# ==========================================\n","# 1. ê²½ë¡œ ì„¤ì •\n","# ==========================================\n","local_path = '/content/local_data'\n","val_target_path = os.path.join(local_path, 'Validation')\n","\n","# í˜¹ì‹œ ì°Œêº¼ê¸°ê°€ ìˆë‹¤ë©´ ì‚­ì œ\n","if os.path.exists(val_target_path):\n","    shutil.rmtree(val_target_path)\n","\n","print(f\"ğŸš€ [ê²€ì¦ ë°ì´í„° í™•ë³´] Kaggleì—ì„œ Validation ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\")\n","\n","# ==========================================\n","# 2. ë‹¤ìš´ë¡œë“œ (ì´ë¯¸ ìˆìœ¼ë©´ ìºì‹œ ì‚¬ìš©ë¨)\n","# ==========================================\n","# Kaggle ë°ì´í„°ì…‹ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ (Trainì€ ë®ì–´ì¨ë„ ìƒê´€ì—†ìŒ)\n","!kaggle datasets download -d manjilkarki/deepfake-and-real-images -p {local_path} --unzip\n","\n","# ==========================================\n","# 3. Validation í´ë” êµ¬ì¶œ ì‘ì „\n","# ==========================================\n","# ì••ì¶• í’€ë¦° ì›ë³¸ ê²½ë¡œ: /content/local_data/Dataset/Validation\n","extracted_val_path = os.path.join(local_path, 'Dataset', 'Validation')\n","\n","if os.path.exists(extracted_val_path):\n","    print(\"\\nğŸ“¦ Validation í´ë”ë¥¼ ì´ë™í•©ë‹ˆë‹¤...\")\n","    # Dataset/Validation -> local_data/Validation ìœ¼ë¡œ ì´ë™\n","    shutil.move(extracted_val_path, local_path)\n","\n","    # ì´ì œ í•„ìš” ì—†ëŠ” ê»ë°ê¸°(Dataset) í´ë”ëŠ” ì‚­ì œ\n","    if os.path.exists(os.path.join(local_path, 'Dataset')):\n","        shutil.rmtree(os.path.join(local_path, 'Dataset'))\n","\n","    print(f\"âœ… ì´ë™ ì™„ë£Œ!\")\n","\n","    # íŒŒì¼ ê°œìˆ˜ í™•ì¸\n","    count = sum([len(files) for r, d, files in os.walk(val_target_path)])\n","    print(f\"ğŸ“Š ê²€ì¦ìš© ì´ë¯¸ì§€ ìˆ˜: {count:,}ì¥\")\n","    print(f\"ğŸ‘‰ ê²½ë¡œ: {val_target_path}\")\n","else:\n","    print(\"âš ï¸ ì˜¤ë¥˜: Validation í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UDl2C9MP7UtU","executionInfo":{"status":"ok","timestamp":1767620774590,"user_tz":-540,"elapsed":45845,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"6366485b-f912-4d7b-f849-6bb28f7a9853"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸš€ [ê²€ì¦ ë°ì´í„° í™•ë³´] Kaggleì—ì„œ Validation ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n","Dataset URL: https://www.kaggle.com/datasets/manjilkarki/deepfake-and-real-images\n","License(s): unknown\n","Downloading deepfake-and-real-images.zip to /content/local_data\n"," 94% 1.59G/1.68G [00:02<00:00, 244MB/s] \n","100% 1.68G/1.68G [00:04<00:00, 439MB/s]\n","\n","ğŸ“¦ Validation í´ë”ë¥¼ ì´ë™í•©ë‹ˆë‹¤...\n","âœ… ì´ë™ ì™„ë£Œ!\n","ğŸ“Š ê²€ì¦ìš© ì´ë¯¸ì§€ ìˆ˜: 39,428ì¥\n","ğŸ‘‰ ê²½ë¡œ: /content/local_data/Validation\n"]}]},{"cell_type":"markdown","source":["## 2. ê²€ì¦ ì‹¤í–‰"],"metadata":{"id":"MI4_El8DaEvA"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import timm\n","import os\n","\n","# ==========================================\n","# 1. ì„¤ì • (Epoch 4 ëª¨ë¸ ì‚¬ìš©)\n","# ==========================================\n","BATCH_SIZE = 32\n","IMG_SIZE = 224\n","VAL_PATH = '/content/local_data/Validation'\n","# ì•„ê¹Œ ì €ì¥í•œ Epoch 4 ëª¨ë¸ ê²½ë¡œ\n","MODEL_PATH = '/content/drive/MyDrive/DILAB/OK/hecto-deepfake-detection/models/deepfake_model_epoch_4.pth'\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# ==========================================\n","# 2. ëª¨ë¸ êµ¬ì¡° ì •ì˜ (í•™ìŠµ ë•Œì™€ ë˜‘ê°™ì´!)\n","# ==========================================\n","class DeepfakeDetector(nn.Module):\n","    def __init__(self, model_name='convnextv2_base.fcmae_ft_in22k_in1k', pretrained=False):\n","        super(DeepfakeDetector, self).__init__()\n","        # ê»ë°ê¸°ë§Œ ë§Œë“¤ ê±°ë¼ pretrained=Falseë¡œ í•´ì„œ ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì ˆì•½\n","        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n","\n","        if hasattr(self.backbone, 'head') and hasattr(self.backbone.head, 'fc'):\n","            n_features = self.backbone.head.fc.in_features\n","            self.backbone.head.fc = nn.Identity()\n","        else:\n","            n_features = self.backbone.num_features\n","            self.backbone.reset_classifier(0)\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(n_features, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(512, 128),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(128, 1)\n","        )\n","\n","    def forward(self, x):\n","        features = self.backbone(x)\n","        return self.classifier(features)\n","\n","# ==========================================\n","# 3. ë°ì´í„° ë¡œë“œ (ì •ì§í•œ í‰ê°€)\n","# ==========================================\n","# ê²€ì¦ìš© ì „ì²˜ë¦¬: íšŒì „/ë°˜ì „ ê¸ˆì§€! ì˜¤ì§ í¬ê¸° ì¡°ì ˆë§Œ\n","val_transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(IMG_SIZE),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","print(f\"ğŸš€ ê²€ì¦ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...\")\n","if os.path.exists(VAL_PATH):\n","    real_val_dataset = datasets.ImageFolder(root=VAL_PATH, transform=val_transform)\n","    real_val_loader = DataLoader(real_val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","    print(f\"   ğŸ“‚ ë°ì´í„° ê°œìˆ˜: {len(real_val_dataset):,}ì¥\")\n","    print(f\"   ğŸ·ï¸ í´ë˜ìŠ¤ ë§µí•‘: {real_val_dataset.class_to_idx}\")\n","else:\n","    print(f\"âŒ ì˜¤ë¥˜: ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤ ({VAL_PATH})\")\n","    exit()\n","\n","# ==========================================\n","# 4. ëª¨ë¸ ë¡œë“œ ë° í‰ê°€\n","# ==========================================\n","print(f\"\\nğŸ¤– ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: {os.path.basename(MODEL_PATH)}\")\n","model = DeepfakeDetector().to(device)\n","\n","if os.path.exists(MODEL_PATH):\n","    model.load_state_dict(torch.load(MODEL_PATH))\n","    print(\"   âœ… ê°€ì¤‘ì¹˜(Weights) ë¡œë“œ ì„±ê³µ!\")\n","else:\n","    print(\"   âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤! ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.\")\n","    exit()\n","\n","# í‰ê°€ ì‹œì‘\n","model.eval()\n","correct = 0\n","total = 0\n","\n","print(\"\\nğŸ¯ ì±„ì  ì‹œì‘ (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)...\")\n","with torch.no_grad():\n","    for images, labels in real_val_loader:\n","        images, labels = images.to(device), labels.to(device).float().unsqueeze(1)\n","\n","        outputs = model(images)\n","        predicted = (torch.sigmoid(outputs) > 0.5).float()\n","\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","acc = 100 * correct / total\n","\n","print(\"=\"*50)\n","print(f\"ğŸ† ìµœì¢… ì„±ì í‘œ (Validation Set)\")\n","print(f\"   ì •í™•ë„ (Accuracy): {acc:.2f}%\")\n","print(\"=\"*50)\n","\n","# ê²°ê³¼ í•´ì„\n","if acc >= 90:\n","    print(\"ğŸ‰ ëŒ€ë°•! ì§„ì§œ ì‹¤ë ¥ì…ë‹ˆë‹¤. ëª¨ë¸ì´ ì™„ë²½í•˜ê²Œ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤.\")\n","elif acc >= 70:\n","    print(\"ğŸ‘ ì¤€ìˆ˜í•©ë‹ˆë‹¤. ì‹¤ì „ì—ì„œë„ ì“¸ë§Œí•œ ëª¨ë¸ì…ë‹ˆë‹¤.\")\n","elif acc >= 50:\n","    print(\"ğŸ¤” ì•„ì‰½ë„¤ìš”. ê³¼ì í•©(Overfitting)ì´ ì˜ì‹¬ë©ë‹ˆë‹¤. (ì°ê¸° ìˆ˜ì¤€)\")\n","else:\n","    print(\"ğŸ˜­ ë­”ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DrZXZ_XTZ-TO","executionInfo":{"status":"ok","timestamp":1767621301670,"user_tz":-540,"elapsed":121464,"user":{"displayName":"Di Lab","userId":"16690045528125560783"}},"outputId":"ca9786b5-b67f-4927-fdad-77e90ba91243"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸš€ ê²€ì¦ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...\n","   ğŸ“‚ ë°ì´í„° ê°œìˆ˜: 39,428ì¥\n","   ğŸ·ï¸ í´ë˜ìŠ¤ ë§µí•‘: {'Fake': 0, 'Real': 1}\n","\n","ğŸ¤– ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤: deepfake_model_epoch_4.pth\n","   âœ… ê°€ì¤‘ì¹˜(Weights) ë¡œë“œ ì„±ê³µ!\n","\n","ğŸ¯ ì±„ì  ì‹œì‘ (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)...\n","==================================================\n","ğŸ† ìµœì¢… ì„±ì í‘œ (Validation Set)\n","   ì •í™•ë„ (Accuracy): 98.62%\n","==================================================\n","ğŸ‰ ëŒ€ë°•! ì§„ì§œ ì‹¤ë ¥ì…ë‹ˆë‹¤. ëª¨ë¸ì´ ì™„ë²½í•˜ê²Œ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤.\n"]}]}]}